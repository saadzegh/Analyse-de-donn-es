---
output:
  html_document: default
  pdf_document: default
---
title: "Rapport"
author: "ALIX Claire - ZEGHARI Saad"
institute : "INSA Toulouse"
date: "`r Sys.Date()`"
output: 
  pdf_document :
    toc : TRUE
    toc_depth : 2
    number_section : TRUE
header-includes:
   - \usepackage{dsfont}
   - \usepackage{color}
   - \newcommand{\1}{\mathds{1}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#library(reticulate)
library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(BioStatR)
library(reshape2)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(circlize)
library(ggalluvial)
library(clusterSim)
library(dbscan)
library(seriation)

```
#Description du jeu de données (mettre en titre partie 1)

Dans ce projet, on s'intéresse à la population des gènes d'une plante modèle. On souhaite analyser les données représentant les différences d'expression d'un certain nombre d'individus (gènes) pour différents traitements appliqués.

```{r,eval=T}
data<-read.table("data.txt",header=T, sep=";", stringsAsFactors = T) #stringsAsFactors converti les variables qualitatives en factors
#class(data)
#dim(data)
#summary(data) on en a pas vraiment besoin mais on peut le laisser dans le code
head(data, n=5)
str(data) #techniquement on n'a pas besoin de dim et class parce que str les donne au début et puis names, colnames donnent les noms des variables mais on les voit déjà dans str donc inutile
#names(data)
#colnames(data)
attributes(data) #par contre pour ça, il donne les noms des individus (gènes) donc peut-être à garder juste dans le code
```
Le jeu de données fourni est composé d'un échantillon de n=542 gènes et de 39 variables statistiques qui caractérisent les individus. On observe que les 36 premières variables sont des variables quantitatives continues. Elles permettent d'évaluer les différences d'expression des gènes pour trois traitements appliqués (T1, T2 et T3) durant 6 heures et ceci pour deux réplicats biologiques (R1 et R2).
Les trois dernières variables (ExpT1, ExpT2 et ExpT3) sont des variables qualitatives (ORDINALES OU NOMINALES JE SAIS PAS TROP) dont les trois modalités sont : "Non", "Sous" et "Sur". Ces dernières représentent pour chaque traitement la décision si le gène est sur-exprimé, sous-exprimé ou non-exprimé à 6h.

#A verifier que tout le vocabulaire soit bien utilisé et que la description est assez claire, concise et complète + fautes d'orthographe maybe (demander à chatgpt parce que flemme)


```{r,eval=F}
#Tout ça rentre également dans la dscription du jeu de données du dessus mais pas forcément utile car l'info est déjà donnée par le str(data) du dessus

#data$ExpT1 <- as.factor(data$ExpT1) inutile car déjà fait quand on lit les données
levels(data$ExpT1)
#data$ExpT2 <- as.factor(data$ExpT2)
levels(data$ExpT2)
#data$ExpT3 <- as.factor(data$ExpT3)
levels(data$ExpT3)
```
#Analyse uni-dimensionnelle et bi-dimensionnelle

Il faut ajouter des graphes pour l'analyse uni-dimensionnelle (voir avec Tessa ce qu'on peut mettre mais notamment les graphes de fréquences/effectifs des trois variables qualitatives et voir dans le cours ce qui peut être intéressant à exploiter) puis voir pour les quantitatives
Peut-être faire un histogramme ou un graphe de la focntion de répartition empirique pour deux ou trois variables pour tester ce que ça donne
NE PAS OUBLIER de faire le truc qui nous dit si il faut centrer et réduire les données ou non avant de faire l'ACP (je sais plus ce que c'était)
```{r,eval=F}
Eff1<-table(data$ExpT1)
df<-data.frame(Eff1=c(Eff1),Freq=c(Eff1)/sum(Eff1))
knitr::kable(t(df))

Eff2<-table(data$ExpT2)
df<-data.frame(Eff2=c(Eff2),Freq=c(Eff2)/sum(Eff2))
knitr::kable(t(df))

Eff3<-table(data$ExpT3)
df<-data.frame(Eff3=c(Eff3),Freq=c(Eff3)/sum(Eff3))
knitr::kable(t(df))

```

```{r}
#On a regardé ça avec Tessa, pas sures de son utilité mais y'a moyen de trouver une interprétation logique avec les différences entre les différents boxplots
#C'est du bi-dimensionnel par contre, je ne sais pas si il faut séparer les deux et faire deux parties ou laisser comme ça mais on moins bien organiser le code lol

ggplot(data,aes(x=ExpT1,y=T1_6H_R1 ))+geom_boxplot()
ggplot(data,aes(x=ExpT2,y=T2_6H_R1))+geom_boxplot()
ggplot(data,aes(x=ExpT3,y=T3_6H_R1 ))+geom_boxplot()
ggplot(data,aes(x=ExpT1,y=T1_6H_R2 ))+geom_boxplot()
ggplot(data,aes(x=ExpT2,y=T2_6H_R2))+geom_boxplot()
ggplot(data,aes(x=ExpT3,y=T3_6H_R2 ))+geom_boxplot()
```
```{r}
#mettre les deux boxplots sur deux graphes différents pour que ce soit plus lisible
data1 <- melt(data[, -c(19:39)])
plot1 <- ggplot(data1, aes(x = variable, y = value)) + geom_boxplot()

data2 <- melt(data[, -c(1:18,37:39)])
plot2 <- ggplot(data2, aes(x = variable, y = value)) + geom_boxplot()
grid.arrange(plot1,plot2)

```
J'ai fait un graphe avec les boxplots des variables du premier replicat et un autre avec les variables du deuxième réplicat et je trouve que les deux graphes se ressemblent pas mal
```{r}
corrplot(cor(data[, -c(37:39)]), method = "ellipse")
```
#Garder le grand pour interpréter que T1 du replicat 1 est pas super corrélé au T1 du réplicat 2 maybe si on a la place et que c'est vraiment intéressant

```{r}
cor1<-corrplot(cor(data[, c(1:18)]), method = "ellipse")
```
```{r}
cor2<-corrplot(cor(data[, c(19:36)]), method = "ellipse")
```
G séparé les 2 exp en 2, c plus simple lolilol (mais on perd en zozo)

On perd les correlations entre la 1ere et la 2eme experience.

```{r,eval=F}
dataScale<-scale(data[,-c(37:39)], center = TRUE , scale = FALSE)
round(apply(dataScale,2,mean))

#Pas nécéssaire
```

ACP CENTRéE

```{r,eval=F}
respca<-PCA(data,quali.sup=c(37:39),scale.unit = F,graph=F)
#respca<-PCA(data,quanti.sup=c(1:18),scale.unit = F,graph=F) Je suis bebete
respca$eig
fviz_eig(respca)

```

```{r,eval=F}
#plot(respca,choix="varcor") 
fviz_pca_var(respca) #graphique des corrélations entre les variables initiales et les méta-variables => Illisible

corrplot(respca$var$cor,method="ellipse")  #les corrélations des variables initiales avec toutes les méta-variables => Plus lisible (même si c pas ouf)

fviz_pca_ind(respca,col.ind="contrib",geom=c("point"))
fviz_pca_ind(respca,geom=c("point"),select.ind = list(cos2=0.95))


#ATTENTION : problème d'overflow, à regler
```

ACP CENTRéE REUDITE


```{r,eval=F}

respca2<-PCA(data,quali.sup=c(37:39),scale.unit=T,graph=F)
respca2$eig
fviz_eig(respca2)

```

```{r,eval=F}
#plot(respca2,choix="varcor") 
fviz_pca_var(respca2) #graphique des corrélations entre les variables initiales et les méta-variables => Illisible

corrplot(respca2$var$cor,method="ellipse")  #les corrélations des variables initiales avec toutes les méta-variables => Plus lisible (même si c pas ouf)

fviz_pca_ind(respca2,col.ind="contrib",geom=c("point"))
fviz_pca_ind(respca2,geom=c("point"),select.ind = list(cos2=0.95))
```




TENTATIVE DE KmEANS
```{r,eval=F}
reskmeans<-kmeans(dataScale,4) 
fviz_pca_ind(respca,habillage=as.factor(reskmeans$cluster) ,geom=c("point"))
```
```{r,eval=F}
fviz_cluster(reskmeans,data=dataScale,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")
fviz_pca_ind(respca,col.ind=as.factor(reskmeans$cluster),
             geom = c("point"),axes=c(1,2))
```


Méthode PAM (approximative)
```{r,eval=F}

Kmax<-15
resPAMcl<-matrix(0,nrow=nrow(data),ncol=Kmax-1)
Silhou<-NULL
for (k in 2:Kmax){
  resaux<-pam(dataScale,k, metric="euclidean")
  resPAMcl[,k-1]<-resaux$clustering
  aux<-silhouette(resPAMcl[,k-1], daisy(dataScale))
  Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")

#on a le coude à 4, on prend 4 classes du coup


#Les lignes suivantes font un truc mais g pas encore trop compris
# aux<-silhouette(resPAMcl[,1], daisy(dataScale))
# fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
# 
# adjustedRandIndex(resPAMcl[,1],reskmeanscl[,3])
# table(resPAMcl[,1],reskmeanscl[,3])

```
On a le coude 4, donc on va choisir 4 classes
