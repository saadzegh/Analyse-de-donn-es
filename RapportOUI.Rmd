---
title: "Rapport de projet - Analyse de donn√©es"
author: "ALIX Claire - ZEGHARI Saad"
institute : "INSA Toulouse"
date: "`r Sys.Date()`"
output: 
  pdf_document :
    toc : TRUE
    toc_depth : 3
    number_section : TRUE
geometry: margin=0.7in
header-includes:
   - \usepackage{dsfont}
   - \usepackage{color}
   - \newcommand{\1}{\mathds{1}}
---

```{r setup, include=FALSE }
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE,fig.align="center",fig.width=15,fig.height = 6, dpi=300)

#importation des packages utiles au projet
library(reticulate)
library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(BioStatR)
library(reshape2)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(circlize)
library(ggalluvial)
library(clusterSim)
library(seriation)
library(knitr)

```
# Introduction

Dans ce projet, on s'int√©resse √† la population des g√®nes d'une plante mod√®le. On souhaite analyser un jeu de donn√©es repr√©sentant les diff√©rences d'expression d'un certain nombre de g√®nes pour plusieurs traitements appliqu√©s et en tirer des conclusions pertinentes √† propos l'exp√©rience biologique men√©e.

Tout au long de ce rapport, le symbole {\textbf{\textsf{R}}} indique que des informations dans le code ne sont pas transmises dans le rapport.

# Statistiques descriptives

## Description du jeu de donn√©es

```{r,eval=T, echo=FALSE}
#On r√©cup√®re le jeu de donn√©es
data<-read.table("DataProjet3MIC-2425.txt",header=T, sep=";", stringsAsFactors = T)
```
Afin de d√©crire l'ensemble du jeu de donn√©es, nous avons utilis√© quelques commandes {\textbf{\textsf{R}}}.
```{r,eval=T, echo=FALSE, results='hide'}
#commandes utiles pour l'analyse du jeu de donn√©es
head(data)
str(data)
names(data)
colnames(data)
attributes(data)
```
Le jeu de donn√©es fourni est compos√© d'un √©chantillon de 542 individus qui correspondent aux g√®nes de la plante mod√®le et comporte 39 variables statistiques qui caract√©risent les individus. 

Grace √† la commande `str(data)`, on observe que les 36 premi√®res variables sont des variables quantitatives continues (variables nomm√©es Tt_sh_Rr). Ces variables permettent d'√©valuer les divergences d'expression des g√®nes pour trois traitements appliqu√©s (T1, T2 et T3) par rapport √† un √©tat sans traitement de r√©f√©rence. Les donn√©es de chaque traitement ont √©t√© relev√©es durant 6 heures et ceci pour deux r√©plicats biologiques (R1 et R2).

Les trois derni√®res variables (nomm√©es ExpT1, ExpT2 et ExpT3) sont des variables qualitatives nominales dont les trois modalit√©s sont : "Non", "Sous" et "Sur". Ces derni√®res repr√©sentent la d√©cision si le g√®ne est sur-exprim√©, sous-exprim√© ou non-exprim√© √† 6 heures par rapport √† l'√©tat de r√©f√©rence, pour chaque traitement.

Afin de visualiser les donn√©es, les premi√®res lignes du jeu de donn√©es sont affich√©es dans la Table \ref{tab:tabdata}. 
En raison de la grande quantit√© de donn√©es, nous avons choisi de repr√©senter seulement les variables T1_1h_R1 √† T1_6h_R1 et ExpT1 qui donnent un aper√ßu de la structure du jeu de donn√©es pour le r√©plicat R1.

```{r, echo=FALSE, eval=TRUE}
kable(head(data[,c(1:6,37)]),caption="\\label{tab:tabdata}Les premi√®res lignes du jeu de donn√©es.")
```

## Analyse uni-dimensionnelle

Nous commen√ßons par faire quelques statistiques descriptives uni-dimensionnelles afin de prendre en main le jeu de donn√©es.

### Variables qualitatives

```{r echo=FALSE, eval=FALSE}
#Visualisation des modalit√©s des trois variables qualitatives
levels(data$ExpT1)
levels(data$ExpT2)
levels(data$ExpT3)
```

Nous avons √† notre disposition trois variables qualitatives : ExpT1, ExpT2, ExpT3 comme d√©crites pr√©c√©demment {\textbf{\textsf{R}}}. Pour extraire certaines tendances des traitements appliqu√©s, nous analysons les fr√©quences d'apparition des diff√©rentes modalit√©s et nous les repr√©sentons sous forme de diagrammes en secteurs dans la Figure \ref{fig:diagsecteurs}.

```{r ,echo=F, eval=FALSE}
#Tableau des fr√©quences pour les variables qualitatives (non utilis√© dans le rapport)

Eff1<-table(data$ExpT1)
#df1<-data.frame(Eff1=c(Eff1),Freq=c(Eff1)/sum(Eff1))
#knitr::kable(t(df1))

Eff2<-table(data$ExpT2)
#df2<-data.frame(Eff2=c(Eff2),Freq=c(Eff2)/sum(Eff2))
#knitr::kable(t(df2))

Eff3<-table(data$ExpT3)
#df3<-data.frame(Eff3=c(Eff3),Freq=c(Eff3)/sum(Eff3))
#knitr::kable(t(df3))

#On regroupe les trois variables dans un m√™me tableau pour pouvoir comparer les traitements
df<-data.frame(ExpT1=round(c(Eff1)*100/sum(Eff1),digits = 3), ExpT2=round(c(Eff2)*100/sum(Eff2),digits=3), ExpT3=round(c(Eff3)*100/sum(Eff3),digits=3))
knitr::kable(t(df),caption="\\label{tab:tabfreq}Tableau des fr√©quences pour les variables qualitatives (en %)")
```

```{r, echo=FALSE, eval=FALSE}
#barplots des effectifs des variables qualitatives (non utilis√© dans le rapport)
g1 = ggplot(data) + geom_bar(aes(x = ExpT1)) 
g2 = ggplot(data) + geom_bar(aes(x = ExpT2)) 
g3 = ggplot(data) + geom_bar(aes(x = ExpT3)) 
grid.arrange(g1,g2,g3,ncol=3)
```

```{r, echo=FALSE, eval=TRUE, fig.align='center', fig.cap="\\label{fig:diagsecteurs}Diagrammes en secteurs des fr√©quences des variables ExpT1, ExpT2 et ExpT3"}
#Diagrammes en secteurs des fr√©quences pour les variables qualitatives

#Pour ExpT1
df1 <- data.frame(group = levels(data$ExpT1), value = as.vector(table(data$ExpT1)) / nrow(data))
g1pie <- ggplot(df1, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7),  
            size = 6, family = "serif", fontface = "bold") +  #Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT1") 

#Pour ExpT2
df2 <- data.frame(group = levels(data$ExpT2), value = as.vector(table(data$ExpT2)) / nrow(data))
g2pie <- ggplot(df2, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7), 
            size = 6, family = "serif", fontface = "bold") +  #Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    axis.text.y = element_text(size = 10),       #Indicateurs autour du graphique
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT2") 

#Pour ExpT3
df3 <- data.frame(group = levels(data$ExpT3), value = as.vector(table(data$ExpT3)) / nrow(data))
g3pie <- ggplot(df3, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7), 
            size = 6, family = "serif", fontface = "bold") +  # Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    axis.text.y = element_text(size = 10),
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT3") 

#Disposition des graphiques
grid.arrange(g1pie, g2pie, g3pie, ncol = 3)

```
D'apr√®s la Figure \ref{fig:diagsecteurs}, on peut d√©j√† remarquer que les traitements diff√®rent dans la r√©action des g√®nes. En effet, on observe une grande similarit√© entre les traitements T2 et T3 avec des r√©actions r√©parties de fa√ßon quasi-homog√®ne entre les modalit√©s "sous" et "sur" exprim√©. Pour sa part, le traitement T1 n'a aucun effet sur la majorit√© des g√®nes, qui n'expriment pas de diff√©rence particuli√®re par rapport √† l'√©tat de r√©f√©rence (81% de "non" exprim√© pour ExpT1).


### Variables quantitatives

Nous analysons maintenant les variables quantitatives de notre jeu de donn√©es (variables Tt_sh_Rr) individuellement. 

Pour apr√©hender les diff√©rences entre les variables quantitatives et en raison du grand nombre de variables √† analyser, nous avons d√©cid√© de tracer leurs boxplots respectifs, regroup√©s par variables d'un m√™me r√©plicat dans la Figure \ref{fig:boxplots_quantitatives1} et la Figure \ref{fig:boxplots_quantitatives2}. Ceci nous permet de r√©sumer les variables de mani√®re simple et visuelle, d'identifier les valeurs extr√™mes, de comprendre la r√©partition des observations et de comparer les deux r√©plicats ensemble ainsi que les traitements et les heures d'observation. {\textbf{\textsf{R}}}

```{r,echo=F, fig.align="center", fig.width=15, fig.height = 5, fig.cap="\\label{fig:boxplots_quantitatives1}Boxplots des variables quantitatives du r√©plicat R1"}
#On s√©pare les boxplots des deux r√©plicats pour avoir des graphiques plus lisibles et comparables
data1 <- melt(data[, -c(19:39)])
ggplot(data1, aes(x = variable, y = value)) + geom_boxplot()
```

```{r,echo=F, fig.align="center", fig.width=15, fig.height = 5, fig.cap="\\label{fig:boxplots_quantitatives2}Boxplots des variables quantitatives du r√©plicat R2"}
data2 <- melt(data[, -c(1:18,37:39)])
ggplot(data2, aes(x = variable, y = value)) + geom_boxplot()
```
Lorsque l'on compare les boxplots obtenus sur les Figures \ref{fig:boxplots_quantitatives1} et \ref{fig:boxplots_quantitatives2}, on peut observer de grandes similitudes entre les r√©sultats obtenus pour le r√©plicat R1 et ceux du r√©plicat R2, ce qui prouve une certaine coh√©rence de l'exp√©rience men√©e.

Nous pouvons par ailleurs comparer les m√©dianes et les √©carts interquartiles respectifs des variables pour √©valuer la dispersion du jeu de donn√©es. On observe alors que les s√©ries statistiques sont tr√®s variables. En effet, bien qu'elles soient bas√©es sur des √©chelles similaires, les variances des variables correspondant aux traitements T2 et T3 sont plus grandes que les variances des variables du traitement T1.

Autre interpr√©tation

```{r, echo=FALSE, eval=FALSE}
#On compare les indicateurs num√©riques (variances, m√©dianes, moyennes) pour les variables quantitatives

# Calculer les variances pour chaque colonne (variables 1 √† 36)
variances <- apply(data[, 1:36], 2, var)

# Cr√©er un data frame pour ggplot
variance_data <- data.frame(
  variable = names(variances), # Noms des colonnes
  variance = variances         # Variances calcul√©es
)

# Cr√©er le graphique
library(ggplot2)
ggplot(variance_data, aes(x = variable, y = variance)) +
  geom_point(size = 2, color = "purple") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des variances par variable",
    x = "Variable",
    y = "Variance"
  )

#Mettre le logo R
```

```{r, echo=FALSE, eval=FALSE}
# Calculer les m√©dianes pour chaque colonne (variables 1 √† 36)
medians <- apply(data[, 1:36], 2, median)

# Cr√©er un data frame pour ggplot
median_data <- data.frame(
  variable = names(medians), # Noms des colonnes
  median = medians           # M√©dianes calcul√©es
)

# Cr√©er le graphique
library(ggplot2)
ggplot(median_data, aes(x = variable, y = median)) +
  geom_point(size = 2, color = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des m√©dianes par variable",
    x = "Variable",
    y = "M√©diane"
  )
```
```{r, echo=FALSE, eval=FALSE}
# Calculer les moyennes pour chaque colonne (variables 1 √† 36)
means <- colMeans(data[, 1:36])

# Cr√©er un data frame pour ggplot
mean_data <- data.frame(
  variable = names(means), # Noms des colonnes
  mean = means             # Moyennes calcul√©es
)

# Cr√©er le graphique
library(ggplot2)
ggplot(mean_data, aes(x = variable, y = mean)) +
  geom_point(size = 2, color = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des moyennes par variable",
    x = "Variable",
    y = "Moyenne"
  )
```


## Analyse bi-dimensionnelle

Nous nous int√©ressons maintenant √† l'analyse bi-dimensionnelle de toutes les variables du jeu de donn√©es.

### Deux variables quantitatives

Nous commen√ßons par analyser les variables quantitatives entre elles. Afin d'analyser les liaisons entre ces variables, nous affichons en Figure \ref{fig:matricecorrelations} la matrice des corr√©lations qui repr√©sente les coefficients de corr√©lations des variables deux √† deux. La corr√©lation mesure la d√©pendance lin√©aire entre deux variables

```{r ,echo=F,fig.align = "center", fig.width=20, fig.height = 10, fig.cap="\\label{fig:matricecorrelations}Matrice des corr√©lations des variables quantitatives"}
corrplot(cor(data[, -c(37:39)]), method = "ellipse")
```
D'apr√®s la Figure \ref{fig:matricecorrelations}, on observe des corr√©lations fortes entre les variables des traitement T2 et T3 tandis que les variables du traitement T1 sont globalement peu corr√©l√©es aux autres variables.

### Deux variables qualitatives

Dans le cas de deux variables qualitatives, on repr√©sente les profils-ligne ou profils-colonne dans la Figure \ref{fig:profil_ligne}.

1. Tableau de contingence
2. Mosaic plot 
3. Indice de liaison 

```{r, fig.height=5, fig.width=15, fig.cap="\\label{fig:profil_ligne}Profils ligne des variables qualitatives"}
#prop.table(table(data$ExpT1,data$ExpT2),margin=1)
g1<-ggplot(data,aes(x=ExpT1,fill=ExpT2))+
geom_bar(position = "fill")

#prop.table(table(data$ExpT1,data$ExpT3),margin=1)
g2<-ggplot(data,aes(x=ExpT1,fill=ExpT3))+
geom_bar(position = "fill")

#prop.table(table(data$ExpT2,data$ExpT3),margin=1)
g3<-ggplot(data,aes(x=ExpT2,fill=ExpT3))+
geom_bar(position = "fill")

grid.arrange(g1,g2,g3,ncol=3)

#mosaicplot(table(data$ExpT1,data$ExpT2)) #illisible
#mosaicplot(table(data$ExpT1,data$ExpT3))
```
Analyse des profils lignes-colonne

### Une variable qualitative et une variable quantitative

Enfin, nous nous int√©ressons √† l'analyse du degr√© de liaison de certaines variables quantitatives avec des variables qualitatives. Figure \ref{fig:boxplots_paralleles}
On trace la distribution de la variable quantitative ùëå en fonction de
chaque modalit√© de la variable qualitative ùëã
1. Repr√©sentation graphique : boxplots parall√®les
Plus les boxplot sont ‚Äúdif√©rents‚Äù, plus X et Y sont li√©s
ATTENTION 1 VARIABLE QUALITATIVE ET 1 VARIABLE QUANTITATIVE SONT LIES PAS CORRELEE !!!!!!!
2. Carr√© du rapport de corr√©lation empirique 
si proche de 0 X et Y ne sont pas li√©es 
si proche de 1 X et Y sont li√©es 

```{r, fig.align='center', fig.cap="\\label{fig:boxplots_paralleles}Boxplots parall√®les"}

plot1<-ggplot(data,aes(x=ExpT1,y=T1_6H_R1 ))+geom_boxplot()
plot2<-ggplot(data,aes(x=ExpT2,y=T2_6H_R1))+geom_boxplot()
plot3<-ggplot(data,aes(x=ExpT3,y=T3_6H_R1 ))+geom_boxplot()
plot4<-ggplot(data,aes(x=ExpT1,y=T1_6H_R2 ))+geom_boxplot()
plot5<-ggplot(data,aes(x=ExpT2,y=T2_6H_R2))+geom_boxplot()
plot6<-ggplot(data,aes(x=ExpT3,y=T3_6H_R2 ))+geom_boxplot()
grid.arrange(plot1,plot2,plot3,plot4,plot5,plot6,ncol=6)
```

# Analyse des Tt_sh_Rr

## Analyse en composantes principales

Menez une analyse en composantes principales o√π les Tt_sH_Rr sont les individus d¬¥ecrits par les
g√®nes.
Pour savoir si utilise l'ACP centr√©e ou l'ACP centr√©e reduite, on compare les pourcentages des variances cumul√©es sur les deux ACP. Car on ne peut pas utiliser des boxplots pour le d√©terminer (trop de variables)

```{r,echo=FALSE, eval=T}
dataACPv<-t(data[c(1:36)]) #on retire les variables qualitatives et on transpose le dataframe 
dim(dataACPv) #on v√©rifie les bonnes dimensions du jeu de donn√©es

#ACP centr√©e
resacpa<-PCA((dataACPv),scale.unit = F,graph=F)
resacpa$eig[1:3,]
```
Au vu du nombre de variables tr√®s √©lev√©, on ne peut pas s'assurer que l'odre de grandeur des variances est similaire? On fait donc une ACP centr√©e r√©duite.
```{r, echo=FALSE, eval=TRUE}
#ACP centr√©e r√©duite
respcav<-PCA((dataACPv),scale.unit = T,graph=F)
respcav$eig[1:3,]
fviz_eig(respcav)
```
Les deux premi√®res composantes principales (Dim1 et Dim2) capturent 71,1 % et 10,5 % de la variance totale, soit un tota cumul√© de 81,6%. Cela signifie que l‚Äôessentiel de l‚Äôinformation contenue dans les donn√©es peut √™tre visualis√© dans un espace bidimensionnel.

AAAAAAAAAAAAAAAAA qui va permettre de r√©cup√©rer plus d'information que l'ACP centr√©√© (variances cumul√©es √† 81,6% contre 80,5%) AAAAAAAAAAAAAAAAAAAAA

```{r,eval=T}
#graphe des variables
fviz_pca_var(respcav) #graphique des corr√©lations entre les variables initiales et les m√©ta-variables => Illisible

#graphe des individus
fviz_pca_ind(respcav,col.ind="contrib",geom=c("point"))

```
Graphe variable => Illisible (rien conclure quant aux variables car bcp trop nombreuses)
=> On fait une analyse s√©par√©e (voit graphe du dessous)

Graphe individu => Pas un regroupement sp√©cifique, on a 2/3. On a une variabilit√© des r√©action en fonction des sp√©cifit√©s des individus.


PARLER DE L'INERTIE
```{r}
# Habillage sur le graphe des individus - R√©plicats
colors <- rep("red", nrow(dataACPv))
colors[1:18] <- "blue"
fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "red" = "red"), 
                     labels = c("R1", "R2")) +
  labs(color = "R√©plicats")
```
Les individus issus des r√©plicats R1 et R2 sont distribu√©s de mani√®re √©quilibr√©e le long des deux dimensions. la variabilit√© n'est pas enti√®rement due aux diff√©rents r√©plicas. 
On peut en conclure que les facteurs des traitements et des heures contribuent de mani√®re significative √† la structure des donn√©es.

```{r}
# Habillage sur le graphe des individus - Traitements
colors <- rep("red", nrow(dataACPv))
colors[c(1:6,19:25)] <- "blue"
colors[c(7:12,26:32)] <- "green"
fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "green" = "green", "red" = "red"), 
                     labels = c("T1", "T2", "T3")) +
  labs(color = "Traitements")
```
Les observations associ√©es au traitement T1 se situent principalement sur la gauche du graphique, tandis que celles des traitements T2 et T3 sont davantage m√©lang√©es √† droite.

Cela refl√®te une diff√©renciation claire entre les effets du traitement T1 et ceux des traitements T2 et T3, ce qui appuie l'observation d√©j√† faite lors de l'analyse bi-dimensionnelle.

```{r}
# Habillage sur le graphe des individus - Heures
colors <- rep("red", nrow(dataACPv))
colors[c(1,7,13,19,25,31)] <- "blue"    # Heure 1
colors[c(2,8,14,20,26,32)] <- "green"   # Heure 2
colors[c(3,9,15,21,27,33)] <- "purple"  # Heure 3
colors[c(4,10,16,22,28,34)] <- "yellow" # Heure 4
colors[c(5,11,17,23,29,35)] <- "orange" # Heure 5

fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "green" = "green", "purple" = "purple", 
                                "yellow" = "yellow", "orange" = "orange", "red" = "red"),
                     labels = c("Heure 1", "Heure 2", "Heure 3", "Heure 4", "Heure 5", "Heure 6")) +
  labs(color = "Heures")
```
A l‚Äôheure 1, toutes les observations, quel que soit le traitement, se regroupent sur la gauche du graphique. On a une faible contribution de la dim1 et une dynamique plus heterog√®ne sur la contribution de la composante dim2. 

Au bout de 2h, on observe que la s√©paration se fait au bout de la deuxi√®me heure.
La contribution par rapport √† dim1 est oppos√©e entre le premier traitement les 2 autres traitements.

Apr√®s cette s√©paration, la variabilit√© des dimensions oscille principalement √† la contribution de dim2 entre chaque heure.


## Clustering

### D√©termination du nombre de classes


```{r}
#Inertie intraclasse

Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(dataACPv),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(dataACPv,k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
g1<-ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse") 
  #ggtitle("Figure 9.1: Inertie intraclasse")
```


```{r}
#silhouette

Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], daisy(dataACPv))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2<-ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")
# ggtitle("Figure 10 : Coefficients silhouette")

aux<-silhouette(reskmeanscl[,3],daisy(dataACPv))
g3<-fviz_silhouette(aux)+
  theme(plot.title = element_text(size =9)) 
#+ ggtitle("Figure 11 : Visualisation des silhouettes")
rm(df,Silhou,aux)

g1 <- g1 + ggtitle("Figure 9.1: Inertie intraclasse") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))
g2 <- g2 + ggtitle("Figure 9.2: Coefficients silhouettes") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))
g3 <- g3 + ggtitle("Figure 9.3 : Visualisation des silhouettes") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))

grid.arrange(g1,g2,g3,ncol=3)
```

Blablabla on choisi 3/4 classes parce que...

### Kmeans

```{r,echo=F,eval=T}
reskmeans<-kmeans(dataACPv,3) 
```


```{r,eval=F}
fviz_cluster(reskmeans,data=dataACPv,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")

fviz_pca_ind(respcav,col.ind=as.factor(reskmeans$cluster),
             geom = c("point"),axes=c(1,2))
```
Interpr√©tation Kmeans

Il faut regarder ce qu'il y a dans reskmeans$cluster pour voir qu'elle variable va dans quelle classe et commenter 

On ne compare pas avec les variables qualitatives car il n'y en a pas 

### Classification hi√©rarchique

```{r}
# dendogramme
dist_dataACPv = dist(dataACPv)

hward<-hclust(dist_dataACPv, method = "ward.D2") 
fviz_dend(hward,show_labels=FALSE)
```
```{r ,fig.cap="A compl√©ter v"}
# A COMPLETER
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(dataACPv, cl= cutree(hward,k)))
}
#On prend k = 3
daux<-data.frame(NbClust=2:Kmax,CH=CH)
g1<-ggplot(daux,aes(x=NbClust,y=CH))+
  geom_line()+
  geom_point()

ClustCH<-cutree(hward,k=3)
g2<-fviz_dend(hward, show_labels = FALSE, k = 3)
g3<-fviz_pca_ind(respcav, geom = c("point"), habillage = as.factor(ClustCH)) 

grid.arrange(g1,g2,g3,ncol=3)
```

# Analyse des g√®nes

Construisez un jeu de donn√©es DataExpMoy contenant la moyenne des expressions sur les r√©plicats de chaque g√®ne, pour chaque traitement et chaque heure. DataExpMoy est donc une matrice de taille G √ó 18. Vous pourrez utiliser les variables ExpT1, ExpT2 et ExpT3 pour commenter vos r√©sultats des questions suivantes.

## Analyse en composantes principales

```{r}
#Cr√©ation du jeu de donn√©es DataExpMoy
dataR1<-data[,1:18]
dataR2<-data[,19:36]
dataACPg<-(dataR1+dataR2)/2
dim(dataACPg) #on a bien Gx18

#On ajoute les variables qualitatives
dataACPg<-cbind(dataACPg, ExpT1=data$ExpT1, ExpT2=data$ExpT2, ExpT3=data$ExpT3)
dim(dataACPg)
```
On fait une ACP centr√©e r√©duite car on a des variances de diff√©rentes √©chelles. Voir outlier figure X.

```{r,eval=T}
#ACP Centr√©e r√©duite
respcag<-PCA(dataACPg,quali.sup=c(19,20,21),scale.unit = TRUE,graph=F)
respcag$eig[1:5,]
fviz_eig(respcag)

```
Les deux premi√®res composantes principales (Dim1 et Dim2) capturent 59,2 % et 22,2 % de la variance totale, soit un total cumul√© de 81,4%. Cela signifie que l‚Äôessentiel de l‚Äôinformation contenue dans les donn√©es peut √™tre visualis√© dans un espace bidimensionnel.

```{r,eval=F}
fviz_pca_var(respcag) #graphique des corr√©lations entre les variables initiales et les m√©ta-variables => Illisible

corrplot(respcag$var$cor,method="ellipse")  #les corr√©lations des variables initiales avec toutes les m√©ta-variables => Plus lisible (m√™me si c pas ouf)

fviz_pca_ind(respcag,col.ind="contrib",geom=c("point"))
```
Cercle des correlations:
Les variables li√©es aux traitements T2 et T3 sont fortement corr√©l√©es et influenc√©es par Dim2, tandis que celles de T1 sont davantage associ√©es √† Dim1. On note une exception pour les g√®nes associ√© √† l‚Äôexp√©rience T3_1H_R1, qui semble influenc√© √† la fois par Dim1 et Dim2.

Graph des individus:
Les points sont en majorit√©s √©loign√©s de l‚Äôorigine. La majorit√© des g√®nes pr√©sentent donc des variations marqu√©es.
Ceux qui sont proches de l'origine, montrent une variation faible, ce qui peut correspondre aux g√®nes du traitement 1.

G√®nes qui influencent dim1 contribue majoritairement de fa√ßon uniforme √† dim2 (faiblement)
Pour les g√®nes avec une faible contribution de dim1, plus de r√©partition sur la contribution de dim2

## Clustering

```{r}
dataACPgC<-scale(dataACPg[,-c(19,20,21)] ,center=TRUE,scale=TRUE)

Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(dataACPg),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(dataACPgC,k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
g1<-ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse")

```

```{r}
# Silhouette 

Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], daisy(dataACPgC))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2<-ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")

aux<-silhouette(reskmeanscl[,3],daisy(dataACPgC))
g3<-fviz_silhouette(aux)+
  theme(plot.title = element_text(size =9))
rm(df,Silhou,aux)


grid.arrange(g1,g2,g3,ncol=3)
```

### Kmeans

```{r,echo=F,eval=T}
reskmeans<-kmeans(dataACPgC,3) 
```


```{r,eval=F}
fviz_cluster(reskmeans,data=dataACPgC,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")

fviz_pca_ind(respcag,col.ind=as.factor(reskmeans$cluster),
             geom = c("point"),axes=c(1,2))
```




### Classification hi√©rarchique

```{r}
# dendogramme
dist_dataACPg = dist(dataACPgC)

hward<-hclust(dist_dataACPg, method = "ward.D2") 
fviz_dend(hward,show_labels=FALSE)
```


```{r}
# A COMPLETER
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(dataACPgC, cl= cutree(hward,k)))
}
#On prend k = 3
daux<-data.frame(NbClust=2:Kmax,CH=CH)
g1<-ggplot(daux,aes(x=NbClust,y=CH))+
  geom_line()+
  geom_point()

ClustCH<-cutree(hward,k=3)
g2<-fviz_dend(hward, show_labels = FALSE, k = 3)
g3<-fviz_pca_ind(respcag, geom = c("point"), habillage = as.factor(ClustCH)) 

grid.arrange(g1,g2,g3,ncol=3)
```

```{r}
clust1<-paste("Cl-K",reskmeans$cluster,sep="")
clust2<-paste("Cl-hi√©rarchique",ClustCH,sep="")
Tab<-melt(table(clust1,clust2))
ggplot(Tab,aes(y=value,axis1=clust1,axis2=clust2))+
  geom_alluvium(aes(fill=clust1))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
```

## Clustering 2 (comparaison avec variable qualitatives) 

```{r}
A<-pam(data[37:39], 3, metric = "euclidean")
A$medoids
adjustedRandIndex(A$clustering,data$ExpT1,data$ExpT2,data$ExpT3)
table(data$ExpT1,data$ExpT2,data$ExpT3,A$clustering)
```


### Partie de comparaison

```{r}
g1<-fviz_pca_ind(respcag,habillage="ExpT1",geom=c("point"))
g2<-fviz_pca_ind(respcag,habillage="ExpT2",geom=c("point"))
g3<-fviz_pca_ind(respcag,habillage="ExpT3",geom=c("point"))
grid.arrange(g1,g2,g3,ncol=3)

```

```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,19]))
g1<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("Figure 15.3")+
  theme(legend.position = "none")
```


```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,20]))
g2<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure15.1 a completer")
  theme(legend.position = "none")

```

```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,21]))
g3<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
grid.arrange(g1,g2,g3,ncol=3)

```
```{r}
clust<-paste("Cl-hi√©rarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,19]))
g1<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("Figure 15.3")+
  theme(legend.position = "none")
```


```{r}
clust<-paste("Cl-hi√©rarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,20]))
g2<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure15.1 a completer")
  theme(legend.position = "none")

```

```{r}
clust<-paste("Cl-hi√©rarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,21]))
g3<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
grid.arrange(g1,g2,g3,ncol=3)

```
