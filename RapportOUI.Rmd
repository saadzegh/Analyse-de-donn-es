---
title: "Rapport de projet - Analyse de données"
author: "ALIX Claire - ZEGHARI Saad"
institute : "INSA Toulouse"
date: "`r Sys.Date()`"
output: 
  pdf_document :
    toc : TRUE
    toc_depth : 3
    number_section : TRUE
geometry: margin=0.7in
header-includes:
   - \usepackage{dsfont}
   - \usepackage{color}
   - \newcommand{\1}{\mathds{1}}
---

```{r setup, include=FALSE }
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE,fig.align="center",fig.width=15,fig.height = 5, dpi=300)

#importation des packages utiles au projet
library(reticulate)
library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(BioStatR)
library(reshape2)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(circlize)
library(ggalluvial)
library(clusterSim)
library(seriation)
library(knitr)
library(stringr)
```
# Introduction

Dans ce projet, on s'intéresse à la population des gènes d'une plante modèle. On souhaite analyser un jeu de données représentant les différences d'expression d'un certain nombre de gènes pour plusieurs traitements appliqués et en tirer des conclusions pertinentes à propos l'expérience biologique menée.

Tout au long de ce rapport, le symbole {\textbf{\textsf{R}}} indique que des informations dans le code ne sont pas transmises dans le rapport.

# Statistiques descriptives

## Description du jeu de données

```{r,eval=T, echo=FALSE}
#On récupère le jeu de données
data<-read.table("DataProjet3MIC-2425.txt",header=T, sep=";", stringsAsFactors = T)
```
Afin de décrire l'ensemble du jeu de données, nous avons utilisé quelques commandes {\textbf{\textsf{R}}}.
```{r,eval=T, echo=FALSE, results='hide'}
#commandes utiles pour l'analyse du jeu de données
head(data)
str(data)
names(data)
colnames(data)
attributes(data)
```
Le jeu de données fourni est composé d'un échantillon de 542 individus qui correspondent aux gènes de la plante modèle et comporte 39 variables statistiques qui caractérisent les individus. 

Grace à la commande `str(data)`, on observe que les 36 premières variables sont des variables quantitatives continues (variables nommées Tt_sh_Rr). Ces variables permettent d'évaluer les divergences d'expression des gènes pour trois traitements appliqués (T1, T2 et T3) par rapport à un état sans traitement de référence. Les données de chaque traitement ont été relevées durant 6 heures et ceci pour deux réplicats biologiques (R1 et R2).

Les trois dernières variables (nommées ExpT1, ExpT2 et ExpT3) sont des variables qualitatives nominales dont les trois modalités sont : "Non", "Sous" et "Sur". Ces dernières représentent la décision si le gène est sur-exprimé, sous-exprimé ou non-exprimé à 6 heures par rapport à l'état de référence, pour chaque traitement.

Afin de visualiser les données, les premières lignes du jeu de données sont affichées dans la Table \ref{tab:tabdata}. 
En raison de la grande quantité de données, nous avons choisi de représenter seulement les variables T1_1h_R1 à T1_6h_R1 et ExpT1 qui donnent un aperçu de la structure du jeu de données pour le réplicat R1.

```{r, echo=FALSE, eval=TRUE}
kable(head(data[,c(1:6,37)]),caption="\\label{tab:tabdata}Les premières lignes du jeu de données.")
```

## Analyse uni-dimensionnelle

Nous commençons par faire quelques statistiques descriptives uni-dimensionnelles afin de prendre en main le jeu de données. {\textbf{\textsf{R}}}

### Variables qualitatives

```{r echo=FALSE, eval=FALSE}
#Visualisation des modalités des trois variables qualitatives
levels(data$ExpT1)
levels(data$ExpT2)
levels(data$ExpT3)
```

Nous avons à notre disposition trois variables qualitatives : ExpT1, ExpT2, ExpT3 comme décrites précédemment. Pour extraire certaines tendances des traitements appliqués, nous analysons les fréquences d'apparition des différentes modalités et nous les représentons sous forme de diagrammes en secteurs dans la Figure \ref{fig:diagsecteurs}.

```{r ,echo=F, eval=FALSE}
#Tableau des fréquences pour les variables qualitatives (non utilisé dans le rapport)

Eff1<-table(data$ExpT1)
#df1<-data.frame(Eff1=c(Eff1),Freq=c(Eff1)/sum(Eff1))
#knitr::kable(t(df1))

Eff2<-table(data$ExpT2)
#df2<-data.frame(Eff2=c(Eff2),Freq=c(Eff2)/sum(Eff2))
#knitr::kable(t(df2))

Eff3<-table(data$ExpT3)
#df3<-data.frame(Eff3=c(Eff3),Freq=c(Eff3)/sum(Eff3))
#knitr::kable(t(df3))

#On regroupe les trois variables dans un même tableau pour pouvoir comparer les traitements
df<-data.frame(ExpT1=round(c(Eff1)*100/sum(Eff1),digits = 3), ExpT2=round(c(Eff2)*100/sum(Eff2),digits=3), ExpT3=round(c(Eff3)*100/sum(Eff3),digits=3))
knitr::kable(t(df),caption="\\label{tab:tabfreq}Tableau des fréquences pour les variables qualitatives (en %)")
```

```{r, echo=FALSE, eval=FALSE}
#barplots des effectifs des variables qualitatives (non utilisé dans le rapport)
g1 = ggplot(data) + geom_bar(aes(x = ExpT1)) 
g2 = ggplot(data) + geom_bar(aes(x = ExpT2)) 
g3 = ggplot(data) + geom_bar(aes(x = ExpT3)) 
grid.arrange(g1,g2,g3,ncol=3)
```

```{r, echo=FALSE, eval=TRUE, fig.align='center', fig.cap="\\label{fig:diagsecteurs}Diagrammes en secteurs des fréquences des variables ExpT1, ExpT2 et ExpT3"}
#Diagrammes en secteurs des fréquences pour les variables qualitatives

#Pour ExpT1
df1 <- data.frame(group = levels(data$ExpT1), value = as.vector(table(data$ExpT1)) / nrow(data))
g1pie <- ggplot(df1, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7),  
            size = 6, family = "serif", fontface = "bold") +  #Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT1") 

#Pour ExpT2
df2 <- data.frame(group = levels(data$ExpT2), value = as.vector(table(data$ExpT2)) / nrow(data))
g2pie <- ggplot(df2, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7), 
            size = 6, family = "serif", fontface = "bold") +  #Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    axis.text.y = element_text(size = 10),       #Indicateurs autour du graphique
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT2") 

#Pour ExpT3
df3 <- data.frame(group = levels(data$ExpT3), value = as.vector(table(data$ExpT3)) / nrow(data))
g3pie <- ggplot(df3, aes(x = "", y = value, fill = group)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), 
            position = position_stack(vjust = 0.7), 
            size = 6, family = "serif", fontface = "bold") +  # Changer la police
  theme_grey(base_size = 15) + 
  theme(
    panel.grid = element_line(color = "gray"),  #Lignes de la grille visibles
    axis.text.y = element_text(size = 10),
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, family = "serif", size = 20, face = "bold")  #Centrer et styliser le titre
  ) +
  labs(fill = NULL) +
  ggtitle("ExpT3") 

#Disposition des graphiques
grid.arrange(g1pie, g2pie, g3pie, ncol = 3)

```
D'après la Figure \ref{fig:diagsecteurs}, on peut déjà remarquer que les traitements diffèrent dans la réaction des gènes. En effet, on observe une grande similarité entre les traitements T2 et T3 avec des réactions réparties de façon quasi-homogène entre les modalités "sous" et "sur" exprimé. Pour sa part, le traitement T1 n'a aucun effet sur la majorité des gènes, qui n'expriment pas de différence particulière par rapport à l'état de référence (81% de "non" exprimé pour ExpT1). Le traitement T1 pourrait ainsi être considéré comme moins efficace par rapport à T2 et T3. T2 semble être un traitement efficace, induisant des changements significatifs dans l'expression des gènes. Comme T3 est une combinaison de T1 et T2, ce traitement semble amplifier l'effet de T2 avec une réponse quasi-identique.


### Variables quantitatives

Nous analysons maintenant les variables quantitatives de notre jeu de données (variables Tt_sh_Rr) individuellement. 

Pour apréhender les différences entre les variables quantitatives et en raison du grand nombre de variables à analyser, nous avons décidé de tracer leurs boxplots respectifs, regroupés par variables d'un même réplicat dans la Figure \ref{fig:boxplots_quantitatives1} et la Figure \ref{fig:boxplots_quantitatives2}. Ceci nous permet de résumer les variables de manière simple et visuelle, d'identifier les valeurs extrêmes, de comprendre la répartition des observations et de comparer les deux réplicats. {\textbf{\textsf{R}}}

```{r,echo=F, fig.align="center", fig.width=15, fig.height = 5, fig.cap="\\label{fig:boxplots_quantitatives1}Boxplots des variables quantitatives du réplicat R1"}
#On sépare les boxplots des deux réplicats pour avoir des graphiques plus lisibles et comparables
data1 <- melt(data[, -c(19:39)])
ggplot(data1, aes(x = variable, y = value)) + geom_boxplot()
```

```{r,echo=F, fig.align="center", fig.width=15, fig.height = 5, fig.cap="\\label{fig:boxplots_quantitatives2}Boxplots des variables quantitatives du réplicat R2"}
data2 <- melt(data[, -c(1:18,37:39)])
ggplot(data2, aes(x = variable, y = value)) + geom_boxplot()
```
Lorsque l'on compare les boxplots obtenus sur les Figures \ref{fig:boxplots_quantitatives1} et \ref{fig:boxplots_quantitatives2}, on peut observer de grandes similitudes entre les résultats obtenus pour le réplicat R1 et ceux du réplicat R2, ce qui prouve une certaine cohérence de l'expérience menée et suggère une reproductibilité des résultats expérimentaux.

Nous pouvons également comparer les médianes et les écarts interquartiles respectifs des variables pour évaluer la dispersion centrale des données. On observe que les traitements T2 et T3 montrent des variances similaires et plus grandes, ce qui est visible sur boxplots plus étendus. Cela reflète une réponse plus variable des gènes pour ces traitements.

Pour T1, les médianes semblent plus proches de zéro, ce qui pourrait indiquer un effet moins marqué par rapport aux traitements T2 et T3 pour lesquels les médianes sont légèrement plus espacées.

Enfin, la présence de nombreux outliers sur les boxplots du traitement T1 peut indiquer que certains gènes réagissent de manière atypique à ce traitement.

```{r, echo=FALSE, eval=FALSE}
#On compare les indicateurs numériques (variances, médianes, moyennes) pour les variables quantitatives

# Calculer les variances pour chaque colonne (variables 1 à 36)
variances <- apply(data[, 1:36], 2, var)

variance_data <- data.frame(
  variable = names(variances),
  variance = variances
)

ggplot(variance_data, aes(x = variable, y = variance)) +
  geom_point(size = 2, color = "purple") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des variances par variable",
    x = "Variable",
    y = "Variance"
  )
```

```{r, echo=FALSE, eval=FALSE}
# Calculer les médianes pour chaque colonne (variables 1 à 36)
medians <- apply(data[, 1:36], 2, median)

median_data <- data.frame(
  variable = names(medians),
  median = medians
)

ggplot(median_data, aes(x = variable, y = median)) +
  geom_point(size = 2, color = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des médianes par variable",
    x = "Variable",
    y = "Médiane"
  )
```

```{r, echo=FALSE, eval=FALSE}
# Calculer les moyennes pour chaque colonne (variables 1 à 36)
means <- colMeans(data[, 1:36])

mean_data <- data.frame(
  variable = names(means),
  mean = means
)

ggplot(mean_data, aes(x = variable, y = mean)) +
  geom_point(size = 2, color = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = "Graphique des moyennes par variable",
    x = "Variable",
    y = "Moyenne"
  )
```

## Analyse bi-dimensionnelle

Nous nous intéressons maintenant à l'analyse bi-dimensionnelle de toutes les variables du jeu de données. {\textbf{\textsf{R}}}

### Deux variables quantitatives

Nous commençons par analyser les variables quantitatives entre elles. Afin d'analyser les liaisons entre ces variables, nous affichons en Figure \ref{fig:matricecorrelations} la matrice des corrélations qui représente les coefficients de corrélations des variables deux à deux et mesure la dépendance linéaire des variables.

```{r ,echo=F,fig.align = "center", fig.width=20, fig.height = 10, fig.cap="\\label{fig:matricecorrelations}Matrice des corrélations des variables quantitatives"}
corrplot(cor(data[, -c(37:39)]), method = "ellipse")
```
D'après la Figure \ref{fig:matricecorrelations}, les corrélations sont fortes entre les variables des traitement T2 et T3, tandis que les variables du traitement T1 sont globalement peu corrélées aux autres variables, peu importe le réplicat considéré. De plus, la majorité des corrélations sont positives.

On observe une forte corrélation entre des variables équivalentes des réplicats R1 et R2 (par exemple les variables T2_6h_R1 et T2_6h_R2), ce qui indique à nouveau que les réplicats sont reproductibles.

Puisque T3 est une combinaison des traitements T1 et T2, nous devrions voir apparaitre des corrélations significatives entre T3 et les variables de T1 et T2. Or ce n'ets le cas que pout T2, ce qui indique que le traitement T1 ne contribue qu'à une faible échelle au résultats du traitement T3.

Enfin, Les variables mesurant le même traitement (T1, T2, ou T3) à des heures différentes ou pour des réplicats différents  présentent des corrélations positives, les mesures sont donc probablement cohérentes.


### Deux variables qualitatives

Dans le cas de deux variables qualitatives, on représente les profils-ligne ou profils-colonne dans la Figure \ref{fig:profils_lignes}.

3. Indice de liaison

```{r, fig.height=5, fig.width=15, fig.cap="\\label{fig:profils_lignes}Profils-lignes des variables qualitatives"}
#Tableaux de contingence et profils-lignes des variables qualitatives

#prop.table(table(data$ExpT1,data$ExpT2),margin=1)
g1<-ggplot(data,aes(x=ExpT1,fill=ExpT2))+
geom_bar(position = "fill")

#prop.table(table(data$ExpT1,data$ExpT3),margin=1)
g2<-ggplot(data,aes(x=ExpT1,fill=ExpT3))+
geom_bar(position = "fill")

#prop.table(table(data$ExpT2,data$ExpT3),margin=1)
g3<-ggplot(data,aes(x=ExpT2,fill=ExpT3))+
geom_bar(position = "fill")

grid.arrange(g1,g2,g3,ncol=3)
```
Les profils-lignes montrent la répartition des modalités des variables qualitatives (ExpT1, ExpT2, ExpT3) et permet de comparer les résultats biologiques de décision obtenus par les trois traitements. L'analyse de la Figure \ref{fig:profils_lignes} 

ExpT1 : La majorité des gènes (81,4 %) sont "Non" exprimés, ce qui montre que le traitement T1 a un effet limité sur l'expression des gènes. Seulement une petite fraction des gènes est "Sur" (10,5 %) ou "Sous" (8,1 %) exprimée.
ExpT2 et ExpT3 : Ces deux traitements ont des profils très similaires, avec une distribution équilibrée entre les gènes "Sur" et "Sous" exprimés (~45-53 %). Cela indique que T2 et T3 déclenchent des réponses significatives pour presque tous les gènes.
Les traitements T2 et T3 montrent une dynamique très similaire, ce qui concorde avec le fait que T3 est une combinaison des effets de T1 et T2. La similarité pourrait indiquer que l'effet de T2 domine dans la combinaison.
Les profils ligne illustrent des tendances qualitatives cohérentes avec les boxplots. Par exemple, les distributions équilibrées des modalités "Sur" et "Sous" pour T2 et T3 sont en accord avec les variances plus importantes observées dans les boxplots.

### Une variable qualitative et une variable quantitative

Enfin, nous nous intéressons à l'analyse du degré de liaison de certaines variables quantitatives avec des variables qualitatives. Figure \ref{fig:boxplots_paralleles}

Boxplots parallèles On trace la distribution de la variable quantitative Y en fonction de chaque modalité de la variable qualitative X

Ces graphiques permettent d’explorer comment les valeurs des variables quantitatives diffèrent en fonction des catégories des variables qualitatives.
Plus les boxplot sont “diférents”, plus X et Y sont liés (pas corrélées)

2. Carré du rapport de corrélation empirique 
si proche de 0 X et Y ne sont pas liées 
si proche de 1 X et Y sont liées 

```{r, fig.align='center', fig.cap="\\label{fig:boxplots_paralleles}Boxplots parallèles"}

plot1<-ggplot(data,aes(x=ExpT1,y=T1_6H_R1 ))+geom_boxplot()
plot2<-ggplot(data,aes(x=ExpT2,y=T2_6H_R1))+geom_boxplot()
plot3<-ggplot(data,aes(x=ExpT3,y=T3_6H_R1 ))+geom_boxplot()
plot4<-ggplot(data,aes(x=ExpT1,y=T1_6H_R2 ))+geom_boxplot()
plot5<-ggplot(data,aes(x=ExpT2,y=T2_6H_R2))+geom_boxplot()
plot6<-ggplot(data,aes(x=ExpT3,y=T3_6H_R2 ))+geom_boxplot()
grid.arrange(plot1,plot2,plot3,plot4,plot5,plot6,ncol=6)
```
Modalité "Non" :

    Pour cette catégorie, les valeurs des boxplots (médiane et dispersion) se regroupent généralement autour de zéro ou restent proches de l’absence de variation. Cela indique une faible différence d’expression pour les gènes non-exprimés.

Modalité "Sous" :

    Les valeurs des boxplots sont souvent négatives, ce qui est attendu puisque ces gènes sont sous-exprimés par définition. Les médianes plus basses et les moustaches vers les valeurs négatives illustrent clairement cet effet.

Modalité "Sur" :

    Les valeurs des boxplots sont généralement positives, avec des médianes plus élevées et une dispersion qui reflète une surexpression des gènes.

# Analyse des Tt_sh_Rr

Nous souhaitons mainteant analyser les variables Tt_sh_Rr en tant qu'individus.

## Analyse en composantes principales

Nous menons tout d'abord une analyse en composantes principales où les variables Tt_sH_Rr sont les individus décrits par les
gènes.

Au vu du nombre de variables très élevé (les 542 gènes) pour cette partie, nous ne pouvons pas constater des dispersions et des échelles différentes entre les variables. Nous avons donc décidé d'appliquer une analyse en composantes principales sur les données centrées et réduites afin de donner un poids équivalent à chacune des variables et éviter ainsi que les variables à grande variance ne dominent l'analyse.

```{r,echo=FALSE, eval=T}
#ACP, création du tableau de données
dataACPv<-t(data[c(1:36)]) #on retire les variables qualitatives et on transpose le dataframe 
dim(dataACPv) #on vérifie les bonnes dimensions du jeu de données

#ACP centrée
#resacpa<-PCA((dataACPv),scale.unit = F,graph=F)
#resacpa$eig[1:3,]
```

```{r, echo=FALSE, eval=TRUE}
#ACP centrée réduite
respcav<-PCA((dataACPv),scale.unit = T,graph=F)
respcav$eig[1:3,]
fviz_eig(respcav)
```
Les deux premières composantes principales (Dim1 et Dim2) capturent 71,1 % et 10,5 % de la variance totale, soit un total cumulé de 81,6%. Cela signifie que l’essentiel de l’information contenue dans les données peut être visualisé dans un espace bidimensionnel.

AAAAAAAAAAAAAAAAA qui va permettre de récupérer plus d'information que l'ACP centréé (variances cumulées à 81,6% contre 80,5%) AAAAAAAAAAAAAAAAAAAAA

```{r,eval=T}

#graphe des individus
g1<-fviz_pca_ind(respcav,geom=c("point"))

#graphe des variables
g2<-fviz_pca_var(respcav,geom=c("point"))
grid.arrange(g1,g2,ncol=2)
```
Le graphique des individus projetés sur les deux premières composantes principales.Nous identifions deux à trois groupes principaux dans cet espace, ce qui souligne des différences claires dans les comportements d'expression des gènes sous les différents traitements.

Le graphique des variables est difficilement interprétable en raison sa densité. Le nombre très élevé des variables. On ne peut pas tirer des conclusions claires sur la contribution des variables ou sur les regroupements entre elles.

```{r}
g1<-fviz_pca_var(respcav,geom=c("point"),habillage = as.factor(data$ExpT1))
g2<-fviz_pca_var(respcav,geom=c("point"),habillage = as.factor(data$ExpT2))
g3<-fviz_pca_var(respcav,geom=c("point"),habillage = as.factor(data$ExpT3))
grid.arrange(g1,g2,g3,ncol=3)
```
ExpT1:
Les variables "Sous" se situent principalement dans la partie supérieure du graphe, indiquant une contribution positive et significative à Dim2.
Les variables "Sur" apparaissent en bas, ce qui reflète une contribution négative à Dim2.
Ainsi lorsqu'on constate des effets sur l'experience EXPT1, ils se manifestent le long de la deuxième composante principale (Dim2).

EXPT2/T3:
Les variables "Sous" sont situées principalement à gauche du graphe, on a donc contribution négative à Dim1.
Les variables "Sur" se trouvent à droite, on a une contribution positive à Dim1.
La première composante principale (Dim1), qui explique 71,1 % de la variance, est fortement influencée par les experiences EXPT2 et EXPT3. Cette dimension distingue clairement les gènes sous-exprimés ("Sous") et surexprimés ("Sur") sous l’effet de ce traitement.

Pour expliquer ces changements, on effectue une analyse qui compare chacune des caractéristiques (replicat, traitement, heures) des 3 experiences.
```{r}
# Habillage sur le graphe des individus - Réplicats
colors <- rep("red", nrow(dataACPv))
colors[1:18] <- "blue"
g1<-fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "red" = "red"), 
                     labels = c("R1", "R2")) +
  labs(color = "Réplicats")
```


```{r}
# Habillage sur le graphe des individus - Traitements
colors <- rep("red", nrow(dataACPv))
colors[c(1:6,19:25)] <- "blue"
colors[c(7:12,26:32)] <- "green"
g2<-fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "green" = "green", "red" = "red"), 
                     labels = c("T1", "T2", "T3")) +
  labs(color = "Traitements")
```


```{r}
# Habillage sur le graphe des individus - Heures
colors <- rep("red", nrow(dataACPv))
colors[c(1,7,13,19,25,31)] <- "blue"    # Heure 1
colors[c(2,8,14,20,26,32)] <- "green"   # Heure 2
colors[c(3,9,15,21,27,33)] <- "purple"  # Heure 3
colors[c(4,10,16,22,28,34)] <- "yellow" # Heure 4
colors[c(5,11,17,23,29,35)] <- "orange" # Heure 5

g3<-fviz_pca_ind(respcav, mean.point=FALSE, geom = "point", col.ind = colors) +
  scale_color_manual(values = c("blue" = "blue", "green" = "green", "purple" = "purple", 
                                "yellow" = "yellow", "orange" = "orange", "red" = "red"),
                     labels = c("Heure 1", "Heure 2", "Heure 3", "Heure 4", "Heure 5", "Heure 6")) +
  labs(color = "Heures") #Mean point sont les points donnant les moyennes

grid.arrange(g1,g2,g3,ncol=3)
```
Graphe Réplicats :
Les individus issus des réplicats R1 et R2 sont distribués de manière équilibrée le long des deux dimensions. la variabilité n'est pas entièrement due aux différents réplicas. 
On peut en conclure que les facteurs des traitements et des heures contribuent de manière significative à la structure des données.

Graphe Traitements:
Les observations associées au traitement T1 se situent principalement sur la gauche du graphique, tandis que celles des traitements T2 et T3 sont davantage mélangées à droite.
Cela reflète une différenciation claire entre les effets du traitement T1 et ceux des traitements T2 et T3, ce qui appuie l'observation déjà faite lors de l'analyse bi-dimensionnelle.

Graphes Heures :
Au bout de la première heure 1, toutes les observations, quel que soit le traitement, se regroupent sur la gauche du graphique. On a donc une faible contribution de Dim1, accompagnée d’une dynamique plus hétérogène sur Dim2.
Dès la deuxième heure, une séparation claire (Alix) apparaît : la contribution par rapport à Dim1 devient opposée entre le premier traitement et les deux autres traitements.
Après cette séparation, la variabilité entre les heures oscille principalement autour de la contribution de Dim2, reflétant une évolution distincte dans les réponses des gènes au fil du temps.

## Clustering

### Détermination du nombre de classes


```{r}
#Inertie intraclasse
set.seed(2)
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(dataACPv),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(dataACPv,k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
g1<-ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse") 
  #ggtitle("Figure 9.1: Inertie intraclasse")
```


```{r}
#silhouette

Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], daisy(dataACPv))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2<-ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")
# ggtitle("Figure 10 : Coefficients silhouette")

aux<-silhouette(reskmeanscl[,2],daisy(dataACPv))
g3<-fviz_silhouette(aux)+
  theme(plot.title = element_text(size =9)) 
#+ ggtitle("Figure 11 : Visualisation des silhouettes")
rm(df,Silhou,aux)

g1 <- g1 + ggtitle("Figure 9.1: Inertie intraclasse") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))
g2 <- g2 + ggtitle("Figure 9.2: Coefficients silhouettes") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))
g3 <- g3 + ggtitle("Figure 9.3 : Visualisation des silhouettes") + theme(plot.title = element_text(hjust = 0.5, vjust = 2))

grid.arrange(g1,g2,g3,ncol=3)
```

En observant le graphique de l'inertie intra-classe, le "coude" apparaît au bout de 3 classes. On décide donc d'en créer 3, ce qui devrait permettre de capturer une quantité significative de variance.

Le graphe de silhouette connait sa chute significative au bour de 3 classes. Ansi les deux graphiques convergent vers l'hypothèse de créer 3 classes différentes dans notre clusering.

### Kmeans

```{r,echo=F,eval=T}
set.seed(25)
reskmeans<-kmeans(dataACPv,3) 
```


```{r,eval=T}
fviz_cluster(reskmeans,data=dataACPv,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")

#fviz_pca_ind(respcav,col.ind=as.factor(reskmeans$cluster), geom = c("point"),axes=c(1,2))
reskmeans$cluster
```
Interprétation Kmeans

Il faut regarder ce qu'il y a dans reskmeans$cluster pour voir qu'elle variable va dans quelle classe et commenter 

On ne compare pas avec les variables qualitatives car il n'y en a pas 

### Classification hiérarchique

```{r}
# dendogramme
dist_dataACPv = dist(dataACPv)

hward<-hclust(dist_dataACPv, method = "ward.D2") 
fviz_dend(hward,show_labels=FALSE)
```
```{r ,fig.cap="A compléter v"}
# A COMPLETER
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(dataACPv, cl= cutree(hward,k)))
}
#On prend k = 3
daux<-data.frame(NbClust=2:Kmax,CH=CH)
g1<-ggplot(daux,aes(x=NbClust,y=CH))+
  geom_line()+
  geom_point()

ClustCH<-cutree(hward,k=3)
g2<-fviz_dend(hward, show_labels = FALSE, k = 3)
g3<-fviz_pca_ind(respcav, geom = c("point"), habillage = as.factor(ClustCH)) 

grid.arrange(g1,g2,g3,ncol=3)
```

# Analyse des gènes

Construisez un jeu de données DataExpMoy contenant la moyenne des expressions sur les réplicats de chaque gène, pour chaque traitement et chaque heure. DataExpMoy est donc une matrice de taille G × 18. Vous pourrez utiliser les variables ExpT1, ExpT2 et ExpT3 pour commenter vos résultats des questions suivantes.

## Analyse en composantes principales

```{r}
#Création du jeu de données DataExpMoy
dataR1<-data[,1:18]
dataR2<-data[,19:36]
dataACPg<-(dataR1+dataR2)/2
dim(dataACPg) #on a bien Gx18

#On ajoute les variables qualitatives
dataACPg<-cbind(dataACPg, ExpT1=data$ExpT1, ExpT2=data$ExpT2, ExpT3=data$ExpT3)
dim(dataACPg)
```
On fait une ACP centrée réduite car on a des variances de différentes échelles. Voir outlier figure X.

```{r,eval=T}
#ACP Centrée réduite
respcag<-PCA(dataACPg,quali.sup=c(19,20,21),scale.unit = TRUE,graph=F)
respcag$eig[1:5,]
fviz_eig(respcag)

```
Les deux premières composantes principales (Dim1 et Dim2) capturent 59,2 % et 22,2 % de la variance totale, soit un total cumulé de 81,4%. Cela signifie que l’essentiel de l’information contenue dans les données peut être visualisé dans un espace bidimensionnel.

```{r,eval=F}
Aux<-rownames(respcag$var$coord)
Traitements<-str_sub(Aux,1,2)
g1<-fviz_pca_var(respcag,habillage=as.factor(Traitements))  #graphique des corrélations entre les variables initiales et les méta-variables => Illisible

corrplot(respcag$var$cor,method="ellipse")  #les corrélations des variables initiales avec toutes les méta-variables => Plus lisible (même si c pas ouf)

g2<-fviz_pca_ind(respcag,col.ind="contrib",geom=c("point"))
grid.arrange(g1,g2,ncol=2)
```
DIM 1 ET 2 représentent le premier plan factoriel (avec DIM 1 et 2 qui sont des métavariables)

Cercle des correlations:
La première composante principale (Dim1) est portée par T2 et T3 qui sont fortement colérées.
La seconde composante principale (dim2) est davantage portée par T1. On remarque que plus les heures avance, plus le traitement 1 se rapproche de l'axe de dim2.
On note une exception pour les gènes associé à l’expérience T3_1H_R1, qui semble influencé à la fois par les deux composantes principales.

Graphe des individus:
La majorité des points sont éloignés de l’origine, ce qui indique que la plupart des gènes présentent des variations marquées dans leurs niveaux d’expression. À l’inverse, les points proches de l’origine montrent des variations faibles, ce qui pourrait correspondre aux gènes influencés par le traitement T1. Les gènes qui contribuent fortement à Dim1 montrent une contribution relativement uniforme à Dim2, mais de faible intensité. En revanche, pour les gènes ayant une faible contribution à Dim1, on observe une répartition plus marquée de leurs contributions le long de Dim2.

## Clustering

Puisqu'on analyse sur tous les gènes car les variables étudient la même chose => On fait le clustering sur les données brutes. Le fait de centrer réduire ferait perdre de l'information

```{r}
set.seed(25)
dataACPgC <- dataACPg[,-c(19,20,21)]

Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(dataACPg),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(dataACPgC,k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
g1<-ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse")

```

```{r}
# Silhouette 

Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], daisy(dataACPgC))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2<-ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")

aux<-silhouette(reskmeanscl[,2],daisy(dataACPgC))
g3<-fviz_silhouette(aux)+
  theme(plot.title = element_text(size =9))
rm(df,Silhou,aux)

aux<-silhouette(reskmeanscl[,3],daisy(dataACPgC))
g4<-fviz_silhouette(aux)+
  theme(plot.title = element_text(size =9))
rm(df,Silhou,aux)


grid.arrange(g1,g2,g3,g4,ncol=4)
```
En observant le graphique de l'inertie intra-classe, le "coude" apparaît autour de 4 classes. On décide donc d'en créer 4, ce qui devrait permettre de capturer une quantité significative de variance.

Le coefficient de silhouette moyen pour 4 classes est légèrement plus élevé que pour d'autres choix de nombre de clusters, ce qui indique une meilleure séparation et cohésion des classes. 


### Kmeans

```{r,echo=F,eval=T}
set.seed(1)
reskmeans<-kmeans(dataACPgC,4) 
```


```{r, echo=F,eval=T}
fviz_cluster(reskmeans,data=dataACPgC,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")

#fviz_pca_ind(respcag,col.ind=as.factor(reskmeans$cluster), geom = c("point"),axes=c(1,2))
reskmeans$cluster
```




### Classification hiérarchique

```{r}
# dendogramme
dist_dataACPg = dist(dataACPgC)

hward<-hclust(dist_dataACPg, method = "ward.D2") 
fviz_dend(hward,show_labels=FALSE)
```


```{r}
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(dataACPgC, cl= cutree(hward,k)))
}
#On prend k = 3
daux<-data.frame(NbClust=2:Kmax,CH=CH)
g1<-ggplot(daux,aes(x=NbClust,y=CH))+
  geom_line()+
  geom_point()

ClustCH<-cutree(hward,k=3)
g2<-fviz_dend(hward, show_labels = FALSE, k = 3)
g3<-fviz_pca_ind(respcag, geom = c("point"), habillage = as.factor(ClustCH)) 

grid.arrange(g1,g2,g3,ncol=3)
```

```{r}
clust1<-paste("Cl-K",reskmeans$cluster,sep="")
clust2<-paste("Cl-hiérarchique",ClustCH,sep="")
Tab<-melt(table(clust1,clust2))
ggplot(Tab,aes(y=value,axis1=clust1,axis2=clust2))+
  geom_alluvium(aes(fill=clust1))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
```



### Partie de comparaison

```{r}
g1<-fviz_pca_ind(respcag,habillage="ExpT1",geom=c("point"))
g2<-fviz_pca_ind(respcag,habillage="ExpT2",geom=c("point"))
g3<-fviz_pca_ind(respcag,habillage="ExpT3",geom=c("point"))
grid.arrange(g1,g2,g3,ncol=3)

```

```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,19]))
g1<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("Figure 15.3")+
  theme(legend.position = "none")
```


```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,20]))
g2<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure15.1 a completer")
  theme(legend.position = "none")

```

```{r}
clust<-paste("Cl-K",reskmeans$cluster,sep="")
Tab<-melt(table(clust,dataACPg[,21]))
g3<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
grid.arrange(g1,g2,g3,ncol=3)

```
```{r}
clust<-paste("Cl-hiérarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,19]))
g1<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("Figure 15.3")+
  theme(legend.position = "none")
```


```{r}
clust<-paste("Cl-hiérarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,20]))
g2<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure15.1 a completer")
  theme(legend.position = "none")

```

```{r}
clust<-paste("Cl-hiérarchique",ClustCH,sep="")
Tab<-melt(table(clust,dataACPg[,21]))
g3<-ggplot(Tab,aes(y=value,axis1=clust,axis2=Var2))+
  geom_alluvium(aes(fill=clust))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  ggtitle("figure 15.2")
  theme(legend.position = "none")
grid.arrange(g1,g2,g3,ncol=3)

```
